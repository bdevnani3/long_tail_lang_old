{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d424df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '/nethome/bdevnani3/flash1/long_tail_lang/')\n",
    "sys.path.insert(0, '/nethome/bdevnani3/flash1/long_tail_lang/data_loader/')\n",
    "from data_loader import clip_dataloaders\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be75fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "import logging\n",
    "logger = logging.getLogger('global')\n",
    "import requests\n",
    "import time\n",
    "import os.path as osp\n",
    "import json\n",
    "import torch\n",
    "import classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1214f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long Tail Embedding Dataset\n",
    "class LTE_Train_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root, image_to_labels, text_prompt_indices=-1):\n",
    "        self.img_path = []\n",
    "        self.labels = []\n",
    "        self.label_names = []\n",
    "        self.text_paths = []\n",
    "        with open(image_to_labels, \"r\") as file:\n",
    "            for line in file:\n",
    "                line = line.strip().split(\" \")\n",
    "                self.img_path.append(line[0])\n",
    "                self.labels.append(line[1])\n",
    "                self.label_names.append(line[2])\n",
    "                if text_prompt_indices == -1:\n",
    "                    temp = line[3:]\n",
    "                    temp = sorted(iterable, key=None,\n",
    "                    self.text_paths.append(line[3:])\n",
    "                else:\n",
    "                    self.text_paths.append[[line[3:][i] for i in text_prompt_indices]]\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        with torch.no_grad():\n",
    "\n",
    "            path = self.img_path[index]\n",
    "            label = self.labels[index]\n",
    "            label_name = self.label_names[index]\n",
    "\n",
    "            text_paths = self.text_paths[index]\n",
    "            le = [torch.load(f) for f in text_paths]\n",
    "            text_embeddings = torch.stack(le).squeeze(1)\n",
    "\n",
    "            sample = torch.load(path)\n",
    "            sample.requires_grad = False\n",
    "\n",
    "            return sample, label, label_name, text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87fdd903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0073,  0.0438, -0.0249,  ...,  0.0172,  0.0136,  0.0833]],\n",
      "       device='cuda:0')\n",
      "696\n",
      "paintbrush\n",
      "tensor([[ 0.0234, -0.0515, -0.1467,  ...,  0.1103, -0.0667,  0.1547],\n",
      "        [ 0.0643, -0.3093, -0.0027,  ...,  0.0196, -0.0815,  0.2244],\n",
      "        [-0.0411, -0.3289, -0.0024,  ...,  0.0095,  0.0018,  0.2661],\n",
      "        ...,\n",
      "        [-0.2747, -0.5425, -0.1719,  ...,  0.0441, -0.1857,  0.3486],\n",
      "        [-0.0346, -0.2211, -0.1965,  ...,  0.0703,  0.0280,  0.1959],\n",
      "        [ 0.0135, -0.3555, -0.1669,  ..., -0.0681, -0.0827,  0.2878]],\n",
      "       device='cuda:0')\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "data_root = '/nethome/bdevnani3/flash1/long_tail_lang/datasets/ImageNet_emb/RN50'\n",
    "image_to_labels = \"/nethome/bdevnani3/flash1/long_tail_lang/datasets/ImageNet_emb/RN50/labels/val/image_to_label.txt\"\n",
    "text_prompt_indices = -1\n",
    "set_ = LTE_Train_Dataset(data_root, image_to_labels, text_prompt_indices=text_prompt_indices)\n",
    "dl = DataLoader(dataset=set_, batch_size=1)\n",
    "for x in dl:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a4f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(\"/nethome/bdevnani3/flash1/long_tail_lang/datasets/ImageNet_emb/RN50/images/val/n03599486/n03599486_2913.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e8eef4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"/nethome/bdevnani3/flash1/long_tail_lang/datasets/ImageNet_emb/RN50/images/val/n03876231/n03876231_2883.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d909bd8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
